{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "356df245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelPreprocessor:\n",
    "    \"\"\"\n",
    "    1. Select fields we want to use as variables for candidate (nfl_id, frame_id, absolute_yardline_number, player_position, play_direction, x, y)\n",
    "    \"\"\"\n",
    "    categorical_cols = ['nfl_id','player_position']\n",
    "    numeric_cols = ['frame_id','absolute_yardline_number','x','y']\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def preprocess(self, input_data_path: str, output_data_path: str):\n",
    "        self.input_data_path = input_data_path \n",
    "        self.output_data_path = output_data_path\n",
    "        train_input = pl.scan_csv(self.input_data_path).filter(pl.col(\"player_to_predict\") == True).with_columns(\n",
    "            pl.lit(0).alias(\"sort_flag\")\n",
    "        )\n",
    "        train_output = pl.scan_csv(self.output_data_path).with_columns(\n",
    "            pl.lit(1).alias(\"sort_flag\")\n",
    "        ) \n",
    "        self.train_data = pl.concat([train_input, train_output], how = \"diagonal\").sort([\"game_id\",\"play_id\",\"nfl_id\",\"sort_flag\",\"frame_id\"])\n",
    "        self.train_data = self.train_data.with_columns(\n",
    "            pl.col(\"player_to_predict\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_to_predict\"),\n",
    "            pl.col(\"play_direction\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"play_direction\"),\n",
    "            pl.col(\"absolute_yardline_number\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"absolute_yardline_number\"),\n",
    "            pl.col(\"player_name\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_name\"),\n",
    "            pl.col(\"player_height\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_height\"),\n",
    "            pl.col(\"player_weight\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_weight\"),\n",
    "            pl.col(\"player_birth_date\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_birth_date\"),\n",
    "            pl.col(\"player_position\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_position\"),\n",
    "            pl.col(\"player_side\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_side\"),\n",
    "            pl.col(\"player_role\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"player_role\"),\n",
    "            pl.col(\"num_frames_output\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"num_frames_output\"),\n",
    "            pl.col(\"ball_land_x\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"ball_land_x\"),\n",
    "            pl.col(\"ball_land_y\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"ball_land_y\"),\n",
    "            pl.col(\"play_id\").cum_count().over([\"game_id\",\"play_id\",\"nfl_id\"]).alias(\"global_frame_id\"),\n",
    "            pl.col(\"a\").fill_null(0.0).alias(\"a\"),\n",
    "            pl.col(\"s\").fill_null(0.0).alias(\"s\"),\n",
    "            pl.col(\"dir\").fill_null(0.0).alias(\"dir\"),\n",
    "            pl.col(\"o\").fill_null(0.0).alias(\"o\"),\n",
    "            ((pl.col(\"game_id\").cast(dtype = pl.Utf8).str.slice(0,8).str.strptime(dtype = pl.Date, format = \"%Y%m%d\") - pl.col(\"player_birth_date\").str.strptime(dtype = pl.Date, format = \"%Y-%m-%d\")).dt.total_days() / 365.25).alias(\"current_player_age\")\n",
    "        ).with_columns(\n",
    "            pl.when(pl.col(\"player_height\").str.len_chars() == 3).then((pl.col(\"player_height\").str.slice(0,1).cast(pl.Int32)*12) + pl.col(\"player_height\").str.slice(2,1).cast(pl.Int32)).otherwise((pl.col(\"player_height\").str.slice(0,1).cast(pl.Int32)*12) + pl.col(\"player_height\").str.slice(2,2).cast(pl.Int32)).alias(\"player_height\"),\n",
    "            pl.col(\"current_player_age\").over([\"game_id\",\"play_id\",\"nfl_id\"]).forward_fill().alias(\"current_player_age\")\n",
    "        ).drop(['player_birth_date','player_name','player_to_predict','game_id','play_id','sort_flag']).collect()\n",
    "        return self.train_data\n",
    "        \n",
    "\n",
    "    def impute(self):\n",
    "        play_dir_vectorizer = layers.TextVectorization(\n",
    "            output_mode = 'multi_hot',\n",
    "            vocabulary = self.train_data['play_direction'].unique().to_list()\n",
    "        )\n",
    "\n",
    "        player_pos_vectorizer = layers.TextVectorization(\n",
    "            output_mode = 'multi_hot',\n",
    "            vocabulary = self.train_data['player_position'].unique().to_list()\n",
    "        )\n",
    "\n",
    "        player_side_vectorizer = layers.TextVectorization(\n",
    "            output_mode = 'multi_hot',\n",
    "            vocabulary = self.train_data['player_side'].unique().to_list()\n",
    "        )\n",
    "\n",
    "        player_role_vectorizer = layers.TextVectorization(\n",
    "            output_mode = 'multi_hot',\n",
    "            vocabulary = self.train_data['player_role'].unique().to_list()\n",
    "        )\n",
    "\n",
    "        nfl_id_vectorizer = layers.TextVectorization(\n",
    "            output_mode = 'int'\n",
    "        )\n",
    "        nfl_id_embedder = layers.Embedding(\n",
    "            input_dim = self.train_data['nfl_id'].n_unique() + 2, # to account for default empty string ('') and unknown vocab ('[UNK]')\n",
    "            output_dim = 8\n",
    "        )\n",
    "        nfl_id_vectorizer.adapt(self.train_data['nfl_id'].cast(pl.Utf8).to_numpy())\n",
    "        vectorized_player_ids = nfl_id_vectorizer(self.train_data['nfl_id'].cast(pl.Utf8).to_list())\n",
    "\n",
    "        encoded_fields = layers.Concatenate(axis=-1)([\n",
    "            play_dir_vectorizer(self.train_data['play_direction']), \n",
    "            player_pos_vectorizer(self.train_data['player_position']),\n",
    "            player_side_vectorizer(self.train_data['player_side']),\n",
    "            player_role_vectorizer(self.train_data['player_role']),\n",
    "            layers.Reshape((8,))(nfl_id_embedder(vectorized_player_ids))\n",
    "        ])\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        standardized_fields = scaler.fit_transform(self.train_data.select([\n",
    "            \"frame_id\",\"absolute_yardline_number\",\"player_height\",\"player_weight\",\n",
    "            \"x\",\"y\",\"s\",\"a\",\"dir\",\"o\",\"num_frames_output\",\"ball_land_x\",\"ball_land_y\",\"global_frame_id\",\"current_player_age\"\n",
    "        ]))\n",
    "        standardized_fields = tf.convert_to_tensor(standardized_fields, dtype = tf.float32)\n",
    "\n",
    "        imputer_train_data = layers.Concatenate(axis=1)([\n",
    "            encoded_fields,\n",
    "            standardized_fields\n",
    "        ])\n",
    "\n",
    "        class NumericEncoder(tf.keras.Model):\n",
    "            def __init__(self, input_dim):\n",
    "                super().__init__()\n",
    "                self.encoder = tf.keras.Sequential([\n",
    "                    layers.Dense(64, activation = 'relu'),\n",
    "                    layers.Dense(32, activation = 'relu')\n",
    "                ])\n",
    "                self.decoder = tf.keras.Sequential([\n",
    "                    layers.Dense(64, activation = 'relu'),\n",
    "                    layers.Dense(input_dim, activation = 'linear')\n",
    "                ])\n",
    "            def call(self, inputs):\n",
    "                encoded = self.encoder(inputs)\n",
    "                decoded = self.decoder(encoded)\n",
    "                return decoded\n",
    "            \n",
    "        autoenc = NumericEncoder(input_dim = imputer_train_data.shape[1])\n",
    "        autoenc.compile(optimizer = 'adam', loss = 'mse')\n",
    "        autoenc.fit(imputer_train_data, imputer_train_data, epochs = 20, batch_size = 2048)\n",
    "        # setup architecture for \n",
    "        \n",
    "\n",
    "    def train_test_split(self, train_pct: float):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7c531ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0226\n",
      "Epoch 2/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8780e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1320e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.9503e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7721e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.9437e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 4.2726e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.9349e-05\n",
      "Epoch 9/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.6540e-05\n",
      "Epoch 10/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.4197e-05\n",
      "Epoch 11/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.4656e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.2781e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.2185e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.1209e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.2435e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.0449e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9602e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.8960e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9832e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m912/912\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9020e-05\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ModelPreprocessor()\n",
    "data = preprocessor.preprocess(input_data_path = './nfl-big-data-bowl-2026-prediction/train/input_*.csv', output_data_path = './nfl-big-data-bowl-2026-prediction/train/output_*.csv')\n",
    "\n",
    "preprocessor.impute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6e0890b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1866376, 8), dtype=float32, numpy=\n",
       "array([[-0.01560276, -0.02569612,  0.03832675, ...,  0.03581517,\n",
       "        -0.02562199, -0.01934985],\n",
       "       [-0.01560276, -0.02569612,  0.03832675, ...,  0.03581517,\n",
       "        -0.02562199, -0.01934985],\n",
       "       [-0.01560276, -0.02569612,  0.03832675, ...,  0.03581517,\n",
       "        -0.02562199, -0.01934985],\n",
       "       ...,\n",
       "       [-0.04462384,  0.03885417,  0.03869602, ..., -0.02074506,\n",
       "         0.02701716, -0.0063647 ],\n",
       "       [-0.04462384,  0.03885417,  0.03869602, ..., -0.02074506,\n",
       "         0.02701716, -0.0063647 ],\n",
       "       [-0.04462384,  0.03885417,  0.03869602, ..., -0.02074506,\n",
       "         0.02701716, -0.0063647 ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical fields to apply encoding\n",
    "# (one hot) = play_direction, player_position, player_side, player_role\n",
    "\n",
    "play_dir_vectorizer = layers.TextVectorization(\n",
    "    output_mode = 'multi_hot',\n",
    "    vocabulary = data['play_direction'].unique().to_list()\n",
    ")\n",
    "\n",
    "player_pos_vectorizer = layers.TextVectorization(\n",
    "    output_mode = 'multi_hot',\n",
    "    vocabulary = data['player_position'].unique().to_list()\n",
    ")\n",
    "\n",
    "player_side_vectorizer = layers.TextVectorization(\n",
    "    output_mode = 'multi_hot',\n",
    "    vocabulary = data['player_side'].unique().to_list()\n",
    ")\n",
    "\n",
    "\n",
    "player_role_vectorizer = layers.TextVectorization(\n",
    "    output_mode = 'multi_hot',\n",
    "    vocabulary = data['player_role'].unique().to_list()\n",
    ")\n",
    "\n",
    "# (embedding) = nfl_id\n",
    "nfl_id_vectorizer = layers.TextVectorization(\n",
    "    output_mode = 'int'\n",
    ")\n",
    "nfl_id_embedder = layers.Embedding(\n",
    "    input_dim = data['nfl_id'].n_unique() + 2, # to account for default empty string ('') and unknown vocab ('[UNK]')\n",
    "    output_dim = 8\n",
    ")\n",
    "nfl_id_vectorizer.adapt(data['nfl_id'].cast(pl.Utf8).to_numpy())\n",
    "vectorized_player_ids = nfl_id_vectorizer(data['nfl_id'].cast(pl.Utf8).to_list())\n",
    "layers.Reshape((8,))(nfl_id_embedder(vectorized_player_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e5657fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "standardized_fields = scaler.fit_transform(data.select([\n",
    "    \"frame_id\",\"absolute_yardline_number\",\"player_height\",\"player_weight\",\n",
    "    \"x\",\"y\",\"s\",\"a\",\"dir\",\"o\",\"num_frames_output\",\"ball_land_x\",\"ball_land_y\",\"global_frame_id\",\"current_player_age\"\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e86111ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
